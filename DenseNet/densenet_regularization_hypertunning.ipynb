{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac525ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 01:54:40.116532: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-24 01:54:40.227402: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-24 01:54:40.306613: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745456080.391440   14249 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745456080.416340   14249 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745456080.582321   14249 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745456080.582346   14249 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745456080.582349   14249 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745456080.582352   14249 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-24 01:54:40.600873: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/tmp/ipykernel_14249/3848676148.py:14: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "# Loading the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import DenseNet121, DenseNet169, DenseNet201\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f175f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745456090.379373   14249 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1745456090.433290   14249 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73efa7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:00<00:00, 720.57it/s]\n",
      "100%|██████████| 354/354 [00:00<00:00, 864.45it/s]\n",
      "100%|██████████| 286/286 [00:00<00:00, 826.82it/s]\n",
      "100%|██████████| 403/403 [00:00<00:00, 783.93it/s]\n",
      "100%|██████████| 347/347 [00:00<00:00, 893.02it/s] \n",
      "100%|██████████| 91/91 [00:00<00:00, 910.05it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 820.75it/s]\n",
      "100%|██████████| 82/82 [00:00<00:00, 924.62it/s]\n",
      "100%|██████████| 68/68 [00:00<00:00, 813.05it/s]\n",
      "100%|██████████| 108/108 [00:00<00:00, 769.58it/s]\n",
      "100%|██████████| 74/74 [00:00<00:00, 910.06it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 767.21it/s]\n",
      "100%|██████████| 46/46 [00:00<00:00, 821.26it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 844.84it/s]\n",
      "100%|██████████| 56/56 [00:00<00:00, 805.66it/s]\n",
      "100%|██████████| 83/83 [00:00<00:00, 685.41it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 815.52it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 822.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6\n",
      "Class names: ['cardboard' 'glass' 'metal' 'paper' 'plastic' 'trash']\n",
      "Training set shape: (1768, 150, 150, 3)\n",
      "Validation set shape: (328, 150, 150, 3)\n",
      "Test set shape: (431, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loading the dataset\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Loading the dataset and preparing it for training\n",
    "train_path = '../dataset_organized/train/'\n",
    "test_path = '../dataset_organized/test/'\n",
    "val_path = '../dataset_organized/validation/'\n",
    "\n",
    "def load_images(path):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for folder in os.listdir(path):\n",
    "        files = os.listdir(path + folder)\n",
    "        for file in tqdm(files):\n",
    "            img = cv2.imread(path + folder + '/' + file)\n",
    "            img = cv2.resize(img, (150, 150))\n",
    "            X.append(img)\n",
    "            y.append(folder)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = load_images(train_path)\n",
    "X_test, y_test = load_images(test_path)\n",
    "X_val, y_val = load_images(val_path)\n",
    "\n",
    "classes_names = np.unique(y_train)\n",
    "num_classes = len(classes_names)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {classes_names}\")\n",
    "\n",
    "# Encoding the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "# One hot encoding the target variable\n",
    "y_train = to_categorical(y_train_encoded)\n",
    "y_test = to_categorical(y_test_encoded)\n",
    "y_val = to_categorical(y_val_encoded)\n",
    "\n",
    "# Normalizing the images\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Enhanced Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f95155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 Complete [00h 18m 02s]\n",
      "val_accuracy: 0.25\n",
      "\n",
      "Best val_accuracy So Far: 0.2591463327407837\n",
      "Total elapsed time: 00h 57m 15s\n",
      "\n",
      "Search: Running Trial #8\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "DenseNet121       |DenseNet169       |densenet_version\n",
      "none              |all               |freeze_option\n",
      "2                 |1                 |num_dense_layers\n",
      "192               |192               |dense_1_units\n",
      "elu               |relu              |dense_1_activation\n",
      "True              |False             |batch_norm_1\n",
      "0.4               |0.2               |dropout_1_rate\n",
      "rmsprop           |rmsprop           |optimizer\n",
      "0.001             |0.001             |learning_rate\n",
      "384               |448               |dense_2_units\n",
      "relu              |relu              |dense_2_activation\n",
      "False             |True              |batch_norm_2\n",
      "0.2               |0.4               |dropout_2_rate\n",
      "384               |384               |dense_3_units\n",
      "relu              |tanh              |dense_3_activation\n",
      "False             |True              |batch_norm_3\n",
      "0.5               |0.2               |dropout_3_rate\n",
      "0.2               |0.4               |momentum\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 3s/step - accuracy: 0.2015 - loss: 2.0310 - val_accuracy: 0.1402 - val_loss: 203.5229\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 137ms/step - accuracy: 0.2500 - loss: 1.8099 - val_accuracy: 0.1707 - val_loss: 247.3533\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 3s/step - accuracy: 0.1976 - loss: 1.9384 - val_accuracy: 0.1738 - val_loss: 3.2791\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 102ms/step - accuracy: 0.2812 - loss: 1.7342 - val_accuracy: 0.1738 - val_loss: 3.4903\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - accuracy: 0.2195 - loss: 1.9147 - val_accuracy: 0.1707 - val_loss: 76.9821\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 102ms/step - accuracy: 0.3438 - loss: 1.6642 - val_accuracy: 0.1707 - val_loss: 95.4673\n",
      "Epoch 7/10\n",
      "\u001b[1m36/55\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 3s/step - accuracy: 0.2138 - loss: 1.8932"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the hypermodel for DenseNet\n",
    "def build_model(hp):\n",
    "    # Select DenseNet variant\n",
    "    densenet_version = hp.Choice('densenet_version', values=['DenseNet121', 'DenseNet169', 'DenseNet201'])\n",
    "    \n",
    "    if densenet_version == 'DenseNet121':\n",
    "        base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "    elif densenet_version == 'DenseNet169':\n",
    "        base_model = DenseNet169(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "    else:\n",
    "        base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    freeze_option = hp.Choice('freeze_option', values=['all', 'partial', 'none'])\n",
    "    \n",
    "    if freeze_option == 'all':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "    elif freeze_option == 'partial':\n",
    "        # Freeze first 75% of the layers\n",
    "        total_layers = len(base_model.layers)\n",
    "        for layer in base_model.layers[:int(total_layers * 0.75)]:\n",
    "            layer.trainable = False\n",
    "        for layer in base_model.layers[int(total_layers * 0.75):]:\n",
    "            layer.trainable = True\n",
    "    else:  # 'none'\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    \n",
    "    # Add custom top layers\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Add dense layers\n",
    "    num_dense_layers = hp.Int('num_dense_layers', min_value=1, max_value=3)\n",
    "    \n",
    "    for i in range(num_dense_layers):\n",
    "        units = hp.Int(f'dense_{i+1}_units', min_value=64, max_value=512, step=64)\n",
    "        activation = hp.Choice(f'dense_{i+1}_activation', values=['relu', 'tanh', 'elu'])\n",
    "        \n",
    "        x = Dense(units=units, activation=activation)(x)\n",
    "        \n",
    "        # Add batch normalization option\n",
    "        use_batch_norm = hp.Boolean(f'batch_norm_{i+1}')\n",
    "        if use_batch_norm:\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "        dropout_rate = hp.Float(f'dropout_{i+1}_rate', min_value=0.2, max_value=0.6, step=0.1)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]))\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = RMSprop(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]))\n",
    "    else:\n",
    "        momentum = hp.Float('momentum', min_value=0.0, max_value=0.9, step=0.1)\n",
    "        opt = SGD(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]), momentum=momentum)\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=20,  # Number of hyperparameter combinations to try\n",
    "    executions_per_trial=1,  # Number of models to train per combination\n",
    "    directory='densenet_tuning',\n",
    "    project_name='densenet_hyperparameter_tuning'\n",
    ")\n",
    "\n",
    "# Print search space summary\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    steps_per_epoch=len(X_train) // 32,\n",
    "    epochs=10,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Print detailed information about the optimal hyperparameters\n",
    "densenet_version = best_hps.get('densenet_version')\n",
    "freeze_option = best_hps.get('freeze_option')\n",
    "num_dense_layers = best_hps.get('num_dense_layers')\n",
    "\n",
    "# Prepare information about dense layers\n",
    "dense_layers_info = \"\"\n",
    "for i in range(num_dense_layers):\n",
    "    units = best_hps.get(f'dense_{i+1}_units')\n",
    "    activation = best_hps.get(f'dense_{i+1}_activation')\n",
    "    batch_norm = best_hps.get(f'batch_norm_{i+1}', False)\n",
    "    dropout_rate = best_hps.get(f'dropout_{i+1}_rate')\n",
    "    \n",
    "    dense_layers_info += f\"\\n- Layer {i+1}: {units} units, activation: {activation}, \"\n",
    "    dense_layers_info += f\"batch normalization: {'Yes' if batch_norm else 'No'}, \"\n",
    "    dense_layers_info += f\"dropout rate: {dropout_rate}\"\n",
    "\n",
    "# Prepare optimizer information\n",
    "optimizer = best_hps.get('optimizer')\n",
    "learning_rate = best_hps.get('learning_rate')\n",
    "momentum_info = \"\"\n",
    "if optimizer == 'sgd':\n",
    "    momentum = best_hps.get('momentum')\n",
    "    momentum_info = f\", momentum: {momentum}\"\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal architecture consists of:\n",
    "\n",
    "Base model: {densenet_version}\n",
    "Freeze option: {freeze_option}\n",
    "\n",
    "Dense layers ({num_dense_layers}):{dense_layers_info}\n",
    "\n",
    "Optimizer: {optimizer} with learning rate: {learning_rate}{momentum_info}\n",
    "\"\"\")\n",
    "\n",
    "# Build the model with the best hyperparameters and train it\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.summary()\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    steps_per_epoch=len(X_train) // 32,\n",
    "    epochs=20,  # Train for longer than during search\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model.save('hypertuned_densenet_model.h5')\n",
    "\n",
    "# Plotting the training and validation accuracy and loss side by side\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Subplot for accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Subplot for loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('densenet_training_history.png')\n",
    "plt.show()\n",
    "\n",
    "# Evaluating the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "\n",
    "# Get training and validation metrics from history\n",
    "train_acc = history.history['accuracy'][-1]\n",
    "val_acc = history.history['val_accuracy'][-1]\n",
    "train_loss = history.history['loss'][-1]\n",
    "val_loss = history.history['val_loss'][-1]\n",
    "\n",
    "print('Training Accuracy:', train_acc)\n",
    "print('Validation Accuracy:', val_acc)\n",
    "print('Training Loss:', train_loss)\n",
    "print('Validation Loss:', val_loss)\n",
    "\n",
    "# Create confusion matrix\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=classes_names, yticklabels=classes_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('densenet_confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=classes_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
